{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: multi_commodity_flow_interdict.py: No such file or directory\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'sample_nodes_data.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5eaadbdd6ff9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiCommodityInterdiction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_nodes_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sample_nodes_commodity_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sample_arcs_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sample_arcs_commodity_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5eaadbdd6ff9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nodefile, node_commodity_file, arcfile, arc_commodity_file, attacks)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \"\"\"\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Read in the node_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Node'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/labtrans/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/labtrans/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/labtrans/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/labtrans/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/labtrans/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'sample_nodes_data.csv' does not exist"
     ]
    }
   ],
   "source": [
    "\n",
    "!cat multi_commodity_flow_interdict.py\n",
    "\n",
    "import pandas\n",
    "import pyomo\n",
    "import pyomo.opt\n",
    "import pyomo.environ as pe\n",
    "import logging\n",
    "\n",
    "class MultiCommodityInterdiction:\n",
    "    \"\"\"A class to compute multicommodity flow interdictions.\"\"\"\n",
    "\n",
    "    def __init__(self, nodefile, node_commodity_file, arcfile, arc_commodity_file, attacks=0):\n",
    "        \"\"\"\n",
    "        All the files are CSVs with columns described below.  Attacks is the number of attacks.\n",
    "\n",
    "        - nodefile:\n",
    "            Node\n",
    "\n",
    "        Every node must appear as a line in the nodefile.  You can have additional columns as well.\n",
    "\n",
    "        - node_commodity_file:\n",
    "            Node,Commodity,SupplyDemand\n",
    "\n",
    "        Every commodity node imbalance that is not zero must appear in the node_commodity_file\n",
    "\n",
    "        - arcfile:\n",
    "            StartNode,EndNode,Capacity,Attackable\n",
    "\n",
    "        Every arc must appear in the arcfile.  Also the arcs total capacity and whether we can attack this arc.\n",
    "\n",
    "        - arc_commodity_file:\n",
    "            StartNode,EndNode,Commodity,Cost,Capacity\n",
    "\n",
    "        This file specifies the costs and capacities of moving each commodity across each arc.  If an (node, node, commodity) tuple does not appear in this file, then it means the commodity cannot flow across that edge.\n",
    "        \"\"\"\n",
    "        # Read in the node_data\n",
    "        self.node_data = pandas.read_csv(nodefile)\n",
    "        self.node_data.set_index(['Node'], inplace=True)\n",
    "        self.node_data.sort_index(inplace=True)\n",
    "        # Read in the node_commodity_data\n",
    "        self.node_commodity_data = pandas.read_csv(node_commodity_file)\n",
    "        self.node_commodity_data.set_index(['Node','Commodity'], inplace=True)\n",
    "        self.node_commodity_data.sort_index(inplace=True)\n",
    "        # Read in the arc_data\n",
    "        self.arc_data = pandas.read_csv(arcfile)\n",
    "        self.arc_data.set_index(['StartNode','EndNode'], inplace=True)\n",
    "        self.arc_data.sort_index(inplace=True)\n",
    "        # Read in the arc_commodity_data\n",
    "        self.arc_commodity_data = pandas.read_csv(arc_commodity_file)\n",
    "        self.arc_commodity_data['xbar'] = 0\n",
    "        self.arc_commodity_data.set_index(['StartNode','EndNode','Commodity'], inplace=True)\n",
    "        self.arc_commodity_data.sort_index(inplace=True)\n",
    "        # Can df.reset_index() to go back\n",
    "\n",
    "        self.attacks = attacks\n",
    "     \n",
    "        self.node_set = self.node_data.index.unique()\n",
    "        self.commodity_set = self.node_commodity_data.index.levels[1].unique()\n",
    "        self.arc_set = self.arc_data.index.unique()\n",
    "        \n",
    "        # Compute nCmax\n",
    "        self.nCmax = len(self.node_set) * self.arc_commodity_data['Cost'].max()\n",
    "\n",
    "        self.createPrimal()\n",
    "        self.createInterdictionDual()\n",
    "\n",
    "\n",
    "    def createPrimal(self):  \n",
    "        \"\"\"Create the primal pyomo model.  \n",
    "        \n",
    "        This is used to compute flows after interdiction.  The interdiction is stored in arc_commodity_data.xbar.\"\"\"\n",
    "\n",
    "        model = pe.ConcreteModel()\n",
    "        # Tell pyomo to read in dual-variable information from the solver\n",
    "        model.dual = pe.Suffix(direction=pe.Suffix.IMPORT) \n",
    "\n",
    "        # Add the sets\n",
    "        model.node_set = pe.Set( initialize=self.node_set )\n",
    "        model.edge_set = pe.Set( initialize=self.arc_set, dimen=2)\n",
    "        model.commodity_set = pe.Set( initialize=self.commodity_set )\n",
    "\n",
    "        # Create the variables\n",
    "        model.y = pe.Var(model.edge_set*model.commodity_set, domain=pe.NonNegativeReals) \n",
    "        model.UnsatSupply = pe.Var(model.node_set*model.commodity_set, domain=pe.NonNegativeReals)\n",
    "        model.UnsatDemand = pe.Var(model.node_set*model.commodity_set, domain=pe.NonNegativeReals)\n",
    "        \n",
    "        # Create the objective\n",
    "        def obj_rule(model):\n",
    "            return  sum( (data['Cost']+data['xbar']*(2*self.nCmax+1))*model.y[e] \n",
    "                        for e,data in self.arc_commodity_data.iterrows()) + sum(self.nCmax*(model.UnsatSupply[n] + model.UnsatDemand[n]) \n",
    "                                                                                for n,data in self.node_commodity_data.iterrows())\n",
    "        model.OBJ = pe.Objective(rule=obj_rule, sense=pe.minimize)\n",
    "\n",
    "        # Create the constraints, one for each node\n",
    "        def flow_bal_rule(model, n,k):\n",
    "            tmp = self.arc_data.reset_index()\n",
    "            successors = tmp.ix[ tmp.StartNode == n, 'EndNode'].values\n",
    "            predecessors = tmp.ix[ tmp.EndNode == n, 'StartNode'].values \n",
    "            lhs = sum(model.y[(i,n,k)] for i in predecessors) - sum(model.y[(n,i,k)] for i in successors) \n",
    "            imbalance = self.node_commodity_data['SupplyDemand'].get((n,k),0)\n",
    "            supply_node = int(imbalance < 0)\n",
    "            demand_node = int(imbalance > 0)\n",
    "            rhs = (imbalance + model.UnsatSupply[n,k]*(supply_node) - model.UnsatDemand[n,k]*(demand_node))\n",
    "            constr = (lhs == rhs)\n",
    "            if isinstance(constr, bool):\n",
    "                return pe.Constraint.Skip\n",
    "            return constr\n",
    "\n",
    "        model.FlowBalance = pe.Constraint(model.node_set*model.commodity_set, rule=flow_bal_rule)\n",
    "        \n",
    "        # Capacity constraints, one for each edge and commodity\n",
    "        def capacity_rule(model, i, j, k):\n",
    "            capacity = self.arc_commodity_data['Capacity'].get((i,j,k),-1)\n",
    "            if capacity < 0:\n",
    "                return pe.Constraint.Skip\n",
    "            return model.y[(i,j,k)] <= capacity\n",
    "\n",
    "        model.Capacity = pe.Constraint(model.edge_set*model.commodity_set, rule=capacity_rule)\n",
    " \n",
    "        # Joint capacity constraints, one for each edge\n",
    "        def joint_capacity_rule(model, i, j):\n",
    "            capacity = self.arc_data['Capacity'].get((i,j), -1)\n",
    "            if capacity < 0:\n",
    "                return pe.Constraint.Skip\n",
    "            return sum(model.y[(i,j,k)] for k in self.commodity_set) <= capacity\n",
    "\n",
    "        model.JointCapacity = pe.Constraint(model.edge_set, rule=joint_capacity_rule)\n",
    "\n",
    "        # Store the model\n",
    "        self.primal = model\n",
    "\n",
    "    def createInterdictionDual(self):\n",
    "        # Create the model\n",
    "        model = pe.ConcreteModel()\n",
    "        \n",
    "        # Add the sets\n",
    "        model.node_set = pe.Set( initialize=self.node_set )\n",
    "        model.edge_set = pe.Set( initialize=self.arc_set, dimen=2)\n",
    "        model.commodity_set = pe.Set( initialize=self.commodity_set )\n",
    "\n",
    "        # Create the variables\n",
    "        model.rho = pe.Var(model.node_set*model.commodity_set, domain=pe.Reals)\n",
    "        model.piSingle = pe.Var(model.edge_set*model.commodity_set, domain=pe.NonPositiveReals)\n",
    "        model.piJoint = pe.Var(model.edge_set, domain=pe.NonPositiveReals)\n",
    "        \n",
    "        model.x = pe.Var(model.edge_set, domain=pe.Binary)\n",
    "\n",
    "        # Create the objective\n",
    "        def obj_rule(model):\n",
    "            return  sum(data['Capacity']*model.piJoint[e] for e,data in self.arc_data.iterrows() if data['Capacity']>=0) +\\\n",
    "                    sum(data['Capacity']*model.piSingle[e] for e,data in self.arc_commodity_data.iterrows() if data['Capacity']>=0)+\\\n",
    "                    sum(data['SupplyDemand']*model.rho[n] for n,data in self.node_commodity_data.iterrows())\n",
    "\n",
    "        model.OBJ = pe.Objective(rule=obj_rule, sense=pe.maximize)\n",
    "\n",
    "        # Create the constraints for y_ijk\n",
    "        def edge_constraint_rule(model, i, j, k):\n",
    "            if (i,j,k) not in self.arc_commodity_data.index:\n",
    "                return pe.Constraint.Skip\n",
    "            attackable = int(self.arc_data['Attackable'].get((i,j),0))\n",
    "            hasSingleCap = int(self.arc_commodity_data['Capacity'].get((i,j,k),-1)>=0)\n",
    "            hasJointCap = int(self.arc_data['Capacity'].get((i,j),-1)>=0)\n",
    "            return model.rho[(j,k)] - model.rho[(i,k)] + model.piSingle[(i,j,k)]*hasSingleCap + model.piJoint[(i,j)]*hasJointCap <=  self.arc_commodity_data['Cost'].get((i,j,k)) + (2*self.nCmax+1)*model.x[(i,j)]*attackable\n",
    "\n",
    "        model.DualEdgeConstraint = pe.Constraint(model.edge_set*model.commodity_set, rule=edge_constraint_rule)\n",
    "        \n",
    "        # Create constraints for the UnsatDemand variables \n",
    "        def unsat_constraint_rule(model, n, k):\n",
    "            if (n,k) not in self.node_commodity_data.index:\n",
    "                return pe.Constraint.Skip\n",
    "            imbalance = self.node_commodity_data['SupplyDemand'].get((n,k),0)\n",
    "            supply_node = int(imbalance < 0)\n",
    "            demand_node = int(imbalance > 0)\n",
    "            if (supply_node):\n",
    "                return -model.rho[(n,k)] <= self.nCmax\n",
    "            if (demand_node):\n",
    "                return model.rho[(n,k)] <= self.nCmax\n",
    "            return pe.Constraint.Skip\n",
    "\n",
    "        model.UnsatConstraint = pe.Constraint(model.node_set*model.commodity_set, rule=unsat_constraint_rule)\n",
    "     \n",
    "        # Create the interdiction budget constraint \n",
    "        def block_limit_rule(model):\n",
    "            model.attacks = self.attacks\n",
    "            return pe.summation(model.x) <= model.attacks\n",
    "\n",
    "        model.BlockLimit = pe.Constraint(rule=block_limit_rule)\n",
    "\n",
    "        # Create, save the model\n",
    "        self.Idual = model\n",
    "\n",
    "    def solve(self, tee=False):\n",
    "        solver = pyomo.opt.SolverFactory('cbc')\n",
    "\n",
    "        # Solve the dual first\n",
    "        self.Idual.BlockLimit.construct()\n",
    "        self.Idual.BlockLimit._constructed = False\n",
    "        del self.Idual.BlockLimit._data[None] \n",
    "        self.Idual.BlockLimit.reconstruct()\n",
    "        self.Idual.preprocess()\n",
    "        results = solver.solve(self.Idual, tee=tee, keepfiles=False, options_string=\"mip_tolerances_integrality=1e-9 mip_tolerances_mipgap=0\")\n",
    "\n",
    "        # Check that we actually computed an optimal solution, load results\n",
    "        if (results.solver.status != pyomo.opt.SolverStatus.ok):\n",
    "            logging.warning('Check solver not ok?')\n",
    "        if (results.solver.termination_condition != pyomo.opt.TerminationCondition.optimal):  \n",
    "            logging.warning('Check solver optimality?')\n",
    "\n",
    "        self.Idual.solutions.load_from(results)\n",
    "        # Now put interdictions into xbar and solve primal\n",
    "       \n",
    "        for e in self.arc_data.index:\n",
    "            self.arc_commodity_data.ix[e,'xbar'] = self.Idual.x[e].value\n",
    "\n",
    "        self.primal.OBJ.construct()\n",
    "        self.primal.OBJ._constructed = False\n",
    "        self.primal.OBJ._init_sense = pe.minimize\n",
    "        del self.primal.OBJ._data[None] \n",
    "        self.primal.OBJ.reconstruct()\n",
    "        self.primal.preprocess()\n",
    "        results = solver.solve(self.primal, tee=tee, keepfiles=False, options_string=\"mip_tolerances_integrality=1e-9 mip_tolerances_mipgap=0\")\n",
    "\n",
    "        # Check that we actually computed an optimal solution, load results\n",
    "        if (results.solver.status != pyomo.opt.SolverStatus.ok):\n",
    "            logging.warning('Check solver not ok?')\n",
    "        if (results.solver.termination_condition != pyomo.opt.TerminationCondition.optimal):  \n",
    "            logging.warning('Check solver optimality?')\n",
    "\n",
    "        self.primal.solutions.load_from(results)\n",
    "\n",
    "    def printSolution(self):\n",
    "        print()\n",
    "        print('Using %d attacks:'%self.attacks)\n",
    "        print()\n",
    "        edges = sorted(self.arc_set)\n",
    "        for e in edges:\n",
    "            if self.Idual.x[e].value > 0:\n",
    "                print('Interdict arc %s -> %s'%(str(e[0]), str(e[1])))\n",
    "        print()\n",
    "        \n",
    "        nodes = sorted(self.node_commodity_data.index)\n",
    "        for n in nodes:\n",
    "            remaining_supply = self.primal.UnsatSupply[n].value\n",
    "            if remaining_supply > 0:\n",
    "                print('Remaining supply of %s on node %s: %.2f'%(str(n[1]), str(n[0]), remaining_supply))\n",
    "        for n in nodes:\n",
    "            remaining_demand = self.primal.UnsatDemand[n].value\n",
    "            if remaining_demand > 0:\n",
    "                print('Remaining demand of %s on node %s: %.2f'%(str(n[1]), str(n[0]), remaining_demand))\n",
    "        print()\n",
    "        \n",
    "        for e0,e1 in self.arc_set:\n",
    "            for k in self.commodity_set:\n",
    "                flow = self.primal.y[(e0,e1,k)].value\n",
    "                if flow > 0:\n",
    "                    print('Flow on arc %s -> %s: %.2f %s'%(str(e0), str(e1), flow, str(k)))\n",
    "        print()\n",
    "\n",
    "        print('----------')\n",
    "        print('Total cost = %.2f (primal) %.2f (dual)'%(self.primal.OBJ(), self.Idual.OBJ()))\n",
    "\n",
    "\n",
    "########################\n",
    "# Now lets do something\n",
    "########################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    m = MultiCommodityInterdiction('sample_nodes_data.csv', 'sample_nodes_commodity_data.csv', 'sample_arcs_data.csv', 'sample_arcs_commodity_data.csv')\n",
    "    m.solve()\n",
    "    m.printSolution()\n",
    "    m.attacks = 1\n",
    "    m.solve()\n",
    "    m.printSolution()\n",
    "    m.attacks = 2\n",
    "    m.solve()\n",
    "    m.printSolution()\n",
    "\n",
    "# In [2]:\n",
    "\n",
    "# !python multi_commodity_flow_interdict.py\n",
    "\n",
    "# WARNING: \"[base]/pyomo/pyomo/solvers/plugins/solvers/CPLEX.py\", 232, _default_executable\n",
    "# \tCould not locate the 'cplex' executable, which is required for solver cplex\n",
    "# Traceback (most recent call last):\n",
    "#   File \"multi_commodity_flow_interdict.py\", line 265, in <module>\n",
    "#     m.solve()\n",
    "#   File \"multi_commodity_flow_interdict.py\", line 197, in solve\n",
    "#     results = solver.solve(self.Idual, tee=tee, keepfiles=False, options_string=\"mip_tolerances_integrality=1e-9 mip_tolerances_mipgap=0\")\n",
    "#   File \"/Users/wehart/home/src/pyomo/python36/src/pyomo/pyomo/opt/base/solvers.py\", line 539, in solve\n",
    "#     self.available(exception_flag=True)\n",
    "#   File \"/Users/wehart/home/src/pyomo/python36/src/pyomo/pyomo/opt/solver/ilmcmd.py\", line 36, in available\n",
    "#     if not pyomo.opt.solver.shellcmd.SystemCallSolver.available(self, exception_flag):\n",
    "#   File \"/Users/wehart/home/src/pyomo/python36/src/pyomo/pyomo/opt/solver/shellcmd.py\", line 122, in available\n",
    "#     raise ApplicationError(msg % self.name)\n",
    "# pyutilib.common._exceptions.ApplicationError: No executable found for solver 'cplex'\n",
    "\n",
    "# In [3]:\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
